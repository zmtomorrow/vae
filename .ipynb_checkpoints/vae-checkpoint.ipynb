{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "import numpy as np\n",
    "from tools import *\n",
    "from distributions import *\n",
    "from utils import *\n",
    "import operator\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "opt= {}\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    opt['device']= torch.device('cuda:0')\n",
    "    opt['if_cuda']=True\n",
    "else:\n",
    "    opt['device']= torch.device('cpu')\n",
    "    opt['if_cuda']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vae(nn.Module):\n",
    "    def __init__(self,opt):\n",
    "        super(vae, self).__init__()\n",
    "        self.z_dim=10\n",
    "        self.en_fc1 = nn.Linear(784, 600)\n",
    "        self.en_fc2 = nn.Linear(600, 400)\n",
    "        self.en_fc3 = nn.Linear(400, 200)\n",
    "        self.en_fc4_1 = nn.Linear(200, self.z_dim)\n",
    "        self.en_fc4_2 = nn.Linear(200, self.z_dim)\n",
    "        self.de_fc1 = nn.Linear(self.z_dim, 200)\n",
    "        self.de_fc2 = nn.Linear(200, 400)\n",
    "        self.de_fc3 = nn.Linear(400, 600)\n",
    "        self.de_fc4_1 = nn.Linear(600, 784)\n",
    "        self.de_fc4_2 = nn.Linear(600, 784)\n",
    "        \n",
    "        self.device=opt['device']\n",
    "        self.if_cuda=opt['if_cuda']\n",
    "        self.prior_mu=torch.zeros(self.z_dim, requires_grad=False)\n",
    "        self.prior_std=torch.ones(self.z_dim, requires_grad=False)\n",
    "        self.params = list(self.parameters())\n",
    "        self.optimizer = optim.Adam(self.params, lr=1e-4)\n",
    "\n",
    "\n",
    "    def posterior(self, x):\n",
    "        h = F.leaky_relu(self.en_fc1(x))\n",
    "        h = F.leaky_relu(self.en_fc2(h))\n",
    "        h = F.leaky_relu(self.en_fc3(h))\n",
    "        mu = self.en_fc4_1(h)\n",
    "        log_std = self.en_fc4_2(h)\n",
    "        return mu, torch.exp(log_std)\n",
    "\n",
    "\n",
    "    def model(self, z):\n",
    "        h = F.leaky_relu(self.de_fc1(z))\n",
    "        h = F.leaky_relu(self.de_fc2(h))\n",
    "        h = F.leaky_relu(self.de_fc3(h))\n",
    "        mean = self.de_fc4_1(h)\n",
    "        log_scale=self.de_fc4_2(h)\n",
    "        return mean.clamp(min=-0.5 + 1. / 512., max=0.5 - 1. / 512.),log_scale\n",
    "    \n",
    "    def loss(self,x):\n",
    "        z_mu, z_std=self.posterior(x)\n",
    "        eps = torch.randn_like(z_mu).to(self.device)\n",
    "        z=eps.mul(z_std).add_(z_mu)\n",
    "        mean,log_scale=self.model(z)\n",
    "        l = discretized_logistic_logp(mean,log_scale,x)\n",
    "        kl=batch_KL_diag_gaussian_std(z_mu,z_std,self.prior_mu.to(self.device),self.prior_std.to(self.device))\n",
    "        loss= torch.mean(-l+kl,dim=0)\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def sample(self,n=100):\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(n, self.z_dim).to(self.device)\n",
    "            x_mean,x_scale=self.model(z)\n",
    "            uniform_noise=torch.clamp(torch.rand_like(x_mean),1e-7,1-1e-7)\n",
    "            x_sample=x_mean + x_scale * (torch.log(uniform_noise) - torch.log(1-uniform_noise))\n",
    "            return torch.floor(x_sample*256) /256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torchvision.datasets.MNIST('../dataset/', train=True, download=False,transform=torchvision.transforms.ToTensor())\n",
    "train_data_list=[]\n",
    "for x,y in train_data:\n",
    "    x=torch.clamp((x*256+torch.rand_like(x))/256,0,1)\n",
    "    train_data_list.append(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-8c715b7d3ed8>\", line 14, in <module>\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/tensor.py\", line 166, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "vae_model = vae(opt).to(opt['device'])\n",
    "loss_list=[]\n",
    "for epoch in range(0,1000):\n",
    "    if epoch>500:\n",
    "        if epoch%50==0:\n",
    "            lr=0.0001/(epoch/100)\n",
    "            vae_model.optimizer = optim.Adam(vae_model.params, lr)\n",
    "    for i in range(0,600):\n",
    "        index=np.random.choice(60000,100)\n",
    "        batch_data_list=[train_data_list[i] for i in index]\n",
    "        batch_data=torch.stack(batch_data_list).view(-1,784).to(opt['device'])\n",
    "        vae_model.optimizer.zero_grad()\n",
    "        loss = vae_model.loss(batch_data)\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        vae_model.optimizer.step()\n",
    "    if epoch%1==0 and epoch!=0:\n",
    "        print('epoch',epoch)\n",
    "        print('loss',loss.item())\n",
    "        plt.plot(loss_list)\n",
    "        plt.show()\n",
    "        \n",
    "        x_sample=vae_model.sample()\n",
    "        show_many(x_sample,10)\n",
    "        torch.save(vae_model.state_dict(), './model_save/vae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mu, z_std=vae_model.posterior(batch_data)\n",
    "eps = torch.randn_like(z_mu).to(vae_model.device)\n",
    "z=eps.mul(z_std).add_(z_mu)\n",
    "mean,log_scale=vae_model.model(z)\n",
    "print(mean)\n",
    "# l = discretized_logistic_logp(mean,log_scale,x)\n",
    "# kl=batch_KL_diag_gaussian_std(z_mu,z_std,self.prior_mu.to(self.device),self.prior_std.to(self.device))\n",
    "# loss= torch.mean(-l+kl,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(100, vae_model.z_dim)\n",
    "    x_mean,x_scale=vae_model.model(z)\n",
    "    uniform_noise=torch.clamp(torch.rand_like(x_mean),1e-7,1-1e-7)\n",
    "    x_sample=x_mean + x_scale * (torch.log(uniform_noise) - torch.log(1-uniform_noise))\n",
    "    x_sample=torch.floor(x_sample*256)/256\n",
    "    show_many(x_mean,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=torchvision.datasets.MNIST('../dataset/', train=False, download=False,transform=torchvision.transforms.ToTensor())\n",
    "# test_data_list=[]\n",
    "# for x,y in test_data:\n",
    "#     test_data_list.append(np.rint(x))\n",
    "    \n",
    "# vae_model = vae(opt).to(opt['device'])\n",
    "# # vae_model.load_state_dict(torch.load(\"./model_save/binary_vae.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
