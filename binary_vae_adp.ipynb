{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Bernoulli\n",
    "from opt import *\n",
    "import numpy as np\n",
    "from tools import *\n",
    "from utils import *\n",
    "from adp_mini import *\n",
    "import operator\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "opt= {}\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    opt['device']= torch.device('cuda:0')\n",
    "    opt['if_cuda']=True\n",
    "else:\n",
    "    opt['device']= torch.device('cpu')\n",
    "    opt['if_cuda']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vae(nn.Module):\n",
    "    def __init__(self,opt):\n",
    "        super(vae, self).__init__()\n",
    "        self.z_dim=10\n",
    "        self.x_std=0.5\n",
    "        self.en_fc1 = nn.Linear(784, 400)\n",
    "        self.en_fc2 = nn.Linear(400, 200)\n",
    "        self.en_fc3_1 = nn.Linear(200, self.z_dim)\n",
    "        self.en_fc3_2 = nn.Linear(200, self.z_dim)\n",
    "        self.de_fc1 = nn.Linear(self.z_dim, 200)\n",
    "        self.de_fc2 = nn.Linear(200, 400)\n",
    "        self.de_fc3 = nn.Linear(400, 784)\n",
    "        \n",
    "        self.device=opt['device']\n",
    "        self.if_cuda=opt['if_cuda']\n",
    "        self.prior_mu=torch.zeros(self.z_dim, requires_grad=False)\n",
    "        self.prior_std=torch.ones(self.z_dim, requires_grad=False)\n",
    "        self.params = list(self.parameters())\n",
    "#         self.optimizer = AGD(self.params, f_star=30,lamb=2.,eta=0.03)\n",
    "#         self.optimizer = optim.SGD(self.params, lr=0.03,momentum=0.0)\n",
    "\n",
    "        self.optimizer = Adam_adp(self.params, eta=0.05, f_star=100)\n",
    "\n",
    "\n",
    "    def posterior(self, x):\n",
    "        h = F.leaky_relu(self.en_fc1(x))\n",
    "        h = F.leaky_relu(self.en_fc2(h))\n",
    "        mu = self.en_fc3_1(h)\n",
    "        log_std = self.en_fc3_2(h)\n",
    "        return mu, torch.exp(log_std)\n",
    "\n",
    "\n",
    "    def model(self, z):\n",
    "        h = F.leaky_relu(self.de_fc1(z))\n",
    "        h = F.leaky_relu(self.de_fc2(h))\n",
    "        logit = self.de_fc3(h)\n",
    "#         logit =F.linear(h, self.en_fc1.weight.t())\n",
    "        return logit\n",
    "    \n",
    "    def evaluate(self,x):\n",
    "        z_mu, z_std=self.posterior(x)\n",
    "        eps = torch.randn_like(z_mu).to(self.device)\n",
    "        z=eps.mul(z_std).add_(z_mu)\n",
    "        logit=self.model(z)\n",
    "        l = torch.sum(Bernoulli(logits=logit).log_prob(x.view(-1, 784)), dim=1)\n",
    "        kl=batch_KL_diag_gaussian_std(z_mu,z_std,self.prior_mu.to(self.device),self.prior_std.to(self.device))\n",
    "        print(kl)\n",
    "        loss= torch.mean(-l+kl,dim=0)\n",
    "        return loss,l,kl,torch.sigmoid(logit)\n",
    "    \n",
    "    def loss(self,x):\n",
    "        z_mu, z_std=self.posterior(x)\n",
    "        eps = torch.randn_like(z_mu).to(self.device)\n",
    "        z=eps.mul(z_std).add_(z_mu)\n",
    "        logit=self.model(z)\n",
    "        l = torch.sum(Bernoulli(logits=logit).log_prob(x.view(-1, 784)), dim=1)\n",
    "        kl=batch_KL_diag_gaussian_std(z_mu,z_std,self.prior_mu.to(self.device),self.prior_std.to(self.device))\n",
    "        loss= torch.mean(-l+kl,dim=0)/np.log(2.)\n",
    "        return loss\n",
    "    \n",
    "    def sample(self):\n",
    "        z = torch.randn(100, self.z_dim).to(self.device)\n",
    "        x_sample=Bernoulli(logits=self.model(z)).sample()\n",
    "        return x_sample.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=torchvision.datasets.MNIST('../data/', train=False, download=False,transform=torchvision.transforms.ToTensor())\n",
    "test_data_list=[]\n",
    "for x,y in test_data:\n",
    "    test_data_list.append(np.rint(x))\n",
    "    \n",
    "test_tensor=torch.stack(test_data_list).view(-1,784)\n",
    "    \n",
    "vae_model = vae(opt).to(opt['device'])\n",
    "# vae_model.load_state_dict(torch.load(\"./model_save/binary_vae.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "loss nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-56ebaa0e9292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mshow_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         torch.save(vae_model.state_dict(), './model_save/binary_vae.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2d324acff163>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mx_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/distributions/bernoulli.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "train_data=torchvision.datasets.MNIST('../data', train=True, download=False,transform=torchvision.transforms.ToTensor())\n",
    "train_data_list=[]\n",
    "for x,y in train_data:\n",
    "    train_data_list.append(np.rint(x))\n",
    "vae_model = vae(opt).to(opt['device'])\n",
    "loss_list=[]\n",
    "test_list=[]\n",
    "lr_list=[]\n",
    "for epoch in range(0,1000):\n",
    "#     if epoch>30:\n",
    "#         vae_model.optimizer = AGD(vae_model.params, f_star=30,lamb=2.,eta=1.0)\n",
    "\n",
    "#     if epoch>120:\n",
    "#         vae_model.optimizer = AGD(vae_model.params, f_star=0,lamb=2.,eta=0.1)\n",
    "    for i in range(0,100):\n",
    "        index=np.random.choice(1000,1000)\n",
    "        batch_data_list=[train_data_list[i] for i in index]\n",
    "        batch_data=torch.stack(batch_data_list).view(-1,784).to(opt['device'])\n",
    "        vae_model.optimizer.zero_grad()\n",
    "        loss = vae_model.loss(batch_data)\n",
    "        loss.backward()\n",
    "#         vae_model.optimizer.step()\n",
    "        _,lr=vae_model.optimizer.step(loss)\n",
    "#     with torch.no_grad():\n",
    "#         test_loss=vae_model.loss(test_tensor)\n",
    "#     test_list.append(test_loss.item())\n",
    "    loss_list.append(loss.item())\n",
    "    lr_list.append(-lr)\n",
    "\n",
    "    if epoch%1==0 and epoch!=0:\n",
    "        print('epoch',epoch)\n",
    "        print('loss',loss.item())\n",
    "        plt.plot(loss_list,label='train')\n",
    "#         plt.plot(test_list,label='test')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(lr_list)\n",
    "        plt.show()\n",
    "        \n",
    "        x_sample=vae_model.sample()\n",
    "        show_many(x_sample,10)\n",
    "#         torch.save(vae_model.state_dict(), './model_save/binary_vae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_list=[193.92770385742188, 148.47991943359375, 127.4101333618164, 106.05278778076172, 89.89850616455078, 76.25437927246094, 66.5630111694336, 56.82843780517578, 52.110843658447266, 161.95359802246094, 70.44442749023438, 47.7762565612793, 38.78557205200195, 35.40535354614258, 33.28783416748047, 31.846569061279297, 30.882841110229492, 29.6651668548584, 29.821638107299805, 29.97037696838379]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adp_list=[296.07421875, 279.4053649902344, 289.00775146484375, 257.3891906738281, 221.60606384277344, 210.6116180419922, 192.2322235107422, 193.0423126220703, 176.72889709472656, 161.51605224609375, 160.9470977783203, 156.37876892089844, 159.46141052246094, 158.47836303710938, 153.67193603515625, 123.41472625732422, 118.97792053222656, 122.40232849121094, 139.07736206054688, 112.28130340576172, 134.1543426513672, 113.97319030761719, 113.08992767333984, 142.6894989013672, 122.46269989013672, 108.391357421875, 115.864990234375, 109.69205474853516, 91.05979919433594, 95.69158935546875, 102.07805633544922, 116.15258026123047, 64.09228515625, 169.35020446777344, 73.46353149414062, 76.96578979492188, 63.743507385253906, 57.512290954589844, 51.989646911621094, 48.81515884399414, 42.68445587158203, 41.54779815673828, 38.62696075439453, 42.848487854003906, 41.1719856262207, 33.70945358276367, 39.96569061279297, 33.142005920410156, 32.40340042114258, 32.84163284301758, 32.05373764038086, 31.77777671813965, 31.138782501220703, 31.009737014770508, 30.48401641845703, 30.63330841064453, 30.315898895263672, 30.147686004638672, 30.100234985351562, 30.100046157836914, 29.952239990234375, 30.219024658203125, 30.03301429748535, 30.161209106445312, 30.10397720336914, 30.244522094726562, 29.966718673706055, 30.035179138183594, 30.16781997680664, 30.08378791809082, 30.103790283203125, 30.10944366455078, 29.911495208740234, 30.073665618896484, 29.988542556762695, 30.064983367919922, 29.91577911376953, 29.973901748657227, 30.017698287963867, 30.007280349731445, 30.17346954345703, 30.05635643005371, 30.016050338745117, 30.001049041748047, 29.85213279724121, 29.878780364990234, 29.92803192138672, 30.13063621520996, 30.036123275756836, 29.981964111328125, 30.547008514404297, 29.931833267211914, 29.923734664916992, 29.991880416870117, 30.069429397583008, 29.869112014770508, 29.95294952392578, 30.150188446044922, 30.091243743896484, 30.110118865966797, 29.972692489624023, 30.02884292602539, 29.923107147216797, 29.951457977294922, 30.009401321411133, 29.842741012573242, 29.949697494506836, 30.21674919128418, 30.19983673095703, 29.89746856689453, 29.76673698425293, 30.22359848022461, 30.07140350341797, 29.87256622314453, 29.843290328979492, 30.05533218383789, 29.838476181030273, 30.20238494873047, 30.08446502685547, 30.024200439453125, 30.04332160949707, 30.195241928100586, 29.968223571777344, 29.840349197387695, 29.96337127685547, 30.063291549682617, 29.936826705932617, 30.132482528686523, 30.101627349853516, 29.883663177490234, 30.073591232299805, 29.95235824584961, 30.061216354370117, 30.22165298461914, 29.76812171936035, 29.982711791992188, 30.126941680908203, 29.9021053314209, 30.014984130859375, 29.986177444458008, 29.948081970214844, 30.15109634399414, 30.04885482788086, 29.993303298950195, 30.165966033935547, 29.924039840698242, 30.034543991088867, 30.062517166137695, 29.855417251586914, 29.955495834350586, 29.92738914489746, 30.23851776123047, 30.029329299926758, 29.9188175201416, 30.10393714904785, 30.193340301513672, 29.826995849609375, 30.061725616455078, 30.017139434814453, 29.824356079101562, 29.875978469848633, 30.070219039916992, 29.93905258178711, 30.166017532348633, 30.215843200683594, 29.899152755737305, 30.191530227661133, 29.864551544189453, 30.103801727294922, 29.915361404418945, 29.854097366333008, 29.98419189453125, 29.89899444580078, 29.952226638793945, 29.935993194580078, 30.028196334838867, 30.06938362121582, 30.185077667236328, 29.847211837768555, 30.04500389099121, 29.970491409301758, 29.907848358154297, 29.8649845123291, 30.073482513427734, 30.01039695739746, 29.975849151611328, 29.79926300048828, 30.136672973632812, 30.037355422973633, 30.020334243774414, 30.057830810546875, 30.00153350830078, 29.88374900817871, 29.766036987304688, 30.06767463684082, 30.16499137878418, 30.053577423095703, 29.977651596069336, 30.144062042236328, 30.057355880737305, 30.020254135131836, 29.985980987548828, 30.13121795654297, 29.936525344848633, 30.074066162109375, 30.308425903320312, 30.01805877685547, 30.03588104248047, 30.029010772705078, 29.74436378479004, 29.981746673583984, 29.848583221435547, 30.140796661376953, 29.879911422729492, 29.98508071899414, 30.013595581054688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(adam_list)\n",
    "plt.plot(adp_list)\n",
    "plt.plot(loss_list)\n",
    "plt.ylim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_t=torch.stack(test_data_list[0:1]).reshape(-1,784)\n",
    "print(vae_model.loss(test_data_t.to(opt['device'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
